from sqlalchemy import exists, select
import typer
import asyncio
import sys

if sys.platform.startswith("win"):
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

from pathlib import Path
from datetime import datetime
from src.config import settings
from src.db.session import init_db, SessionLocal
from src.db.models import Channel
from src.tg_client.client import client
from src.store.redis import _client as redis

from src.crawler.worker import crawl_channel  # –ë—É–≤ src.crawler.worker
from src.ml.ml_worker import main as run_ml_worker  # –ù–æ–≤–∏–π ML –≤–æ—Ä–∫–µ—Ä
from src.utils.split_existing_videos import process_s3
from src.label_bot.bot import main as run_bot


app = typer.Typer(add_help_option=True)

# Redis –∫–ª—é—á—ñ
ML_QUEUE = "fpv:ml_queue"
ML_PROCESSING = "fpv:processing"
ML_STATS = "fpv:ml_stats"


@app.command()
def init():
    """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –ë–î/—Å—Ö–æ–≤–∏—â–∞, —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å–µ—Å—ñ—ó Pyrogram."""
    init_db()
    print("‚úì DB initialized")
    
    # –ü—Ä–æ–≥—Ä—ñ–≤ —Å–µ—Å—ñ—ó Telegram
    async def warm():
        async with client:
            me = await client.get_me()
            print(f"‚úì Telegram session OK: {me.first_name} (ID: {me.id})")
    
    asyncio.run(warm())


@app.command("crawl")
def crawl(
    mode: str = typer.Option("backfill", help="latest|backfill"),
    since: str | None = None,
    continuous: bool = typer.Option(False, help="–ë–µ–∑–ø–µ—Ä–µ—Ä–≤–Ω–∏–π –æ–±—Ö—ñ–¥ –∑ —Ä–æ—Ç–∞—Ü—ñ—î—é")
):
    """
    –ö—Ä–∞—É–ª—ñ–Ω–≥ Telegram –∫–∞–Ω–∞–ª—ñ–≤ –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é —Ä–æ—Ç–∞—Ü—ñ—ó.
    
    Args:
        mode: –†–µ–∂–∏–º –æ–±—Ö–æ–¥—É (latest —Ç—ñ–ª—å–∫–∏ –Ω–æ–≤—ñ, backfill –∑ —ñ—Å—Ç–æ—Ä—ñ—î—é)
        since: –î–∞—Ç–∞ –ø–æ—á–∞—Ç–∫—É –¥–ª—è backfill (YYYY-MM-DD)
        continuous: –ë–µ–∑–ø–µ—Ä–µ—Ä–≤–Ω–∏–π —Ä–µ–∂–∏–º –∑ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ—é —Ä–æ—Ç–∞—Ü—ñ—î—é –∫–∞–Ω–∞–ª—ñ–≤
    """
    async def run():
        # –ß–∏—Ç–∞—î–º–æ seed –∫–∞–Ω–∞–ª–∏
        seeds_file = Path("seeds.txt")
        if not seeds_file.exists():
            print("ERROR: seeds.txt –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
            return
            
        seeds = [
            s.strip() 
            for s in set(seeds_file.read_text(encoding="utf-8").splitlines()) 
            if s.strip() and not s.strip().startswith("#")
        ]
        
        if not seeds:
            print("ERROR: –ñ–æ–¥–Ω–æ–≥–æ –∫–∞–Ω–∞–ª—É –≤ seeds.txt")
            return
        
        print(f"üì° Starting crawler for {len(seeds)} channels")
        print(f"   Mode: {mode}")
        print(f"   Rotation interval: {settings.channel_rotation_interval_hours}h")
        print(f"   ML queue: {ML_QUEUE}")
        
        # –í–∏–∑–Ω–∞—á–∞—î–º–æ –¥–∞—Ç—É –ø–æ—á–∞—Ç–∫—É –¥–ª—è backfill
        backfill_since = None
        if mode == "backfill":
            backfill_since = (
                datetime.fromisoformat(since) 
                if since 
                else datetime.fromisoformat(settings.crawl_backfill_since)
            )
            print(f"   Backfill since: {backfill_since}")
        
        # –†–µ–∂–∏–º –±–µ–∑–ø–µ—Ä–µ—Ä–≤–Ω–æ–≥–æ –æ–±—Ö–æ–¥—É –∑ —Ä–æ—Ç–∞—Ü—ñ—î—é
        if continuous:
            print("\nüîÑ Continuous mode with rotation enabled")
            while True:
                for idx, seed in enumerate(seeds, 1):
                    print(f"\n[{idx}/{len(seeds)}] Processing: {seed}")
                    await crawl_channel(seed, mode=mode, backfill_since=backfill_since)
                    
                print("\n‚úì Completed full rotation, restarting...")
        else:
            # –û–¥–Ω–æ—Ä–∞–∑–æ–≤–∏–π –ø—Ä–æ—Ö—ñ–¥ –ø–æ –≤—Å—ñ—Ö –∫–∞–Ω–∞–ª–∞—Ö
            for idx, seed in enumerate(seeds, 1):
                print(f"\n[{idx}/{len(seeds)}] Processing: {seed}")
                await crawl_channel(seed, mode=mode, backfill_since=backfill_since)
            
            print("\n‚úì Crawling completed")
    
    asyncio.run(run())


@app.command("ml-worker")
def ml_worker():
    """
    –ó–∞–ø—É—Å–∫ ML –≤–æ—Ä–∫–µ—Ä–∞ –¥–ª—è –æ–±—Ä–æ–±–∫–∏ –≤—ñ–¥–µ–æ –∑ Redis —á–µ—Ä–≥–∏.
    
    –í–æ—Ä–∫–µ—Ä:
    - –°–ª—É—Ö–∞—î —á–µ—Ä–≥—É fpv:ml_queue
    - –í–∏—Ç—è–≥—É—î –∫–∞–¥—Ä–∏ –∑ –≤—ñ–¥–µ–æ (FPS –∑ config)
    - –ö–ª–∞—Å–∏—Ñ—ñ–∫—É—î –∫–æ–∂–µ–Ω –∫–∞–¥—Ä
    - –ü–µ—Ä–µ–º—ñ—â—É—î –ø—ñ–¥—Ö–æ–¥—è—â—ñ –≤—ñ–¥–µ–æ –≤ dataset/
    """
    print("ü§ñ Starting ML Worker")
    print(f"   Model: {settings.ml_model_path}")
    print(f"   FPS: {settings.ml_frames_per_second}")
    print(f"   Positive threshold: {settings.ml_positive_threshold} consecutive frames")
    print(f"   Batch size: {settings.ml_batch_size}")
    print(f"   Queue: {ML_QUEUE}")
    print()
    
    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –º–æ–¥–µ–ª—ñ
    model_path = Path(settings.ml_model_path)
    if not model_path.exists():
        print(f"‚ùå ERROR: Model not found at {model_path}")
        print("\nPlease train the model first:")
        print("  python -m src.ml.frame_classifier")
        return
    
    run_ml_worker()


@app.command("queue-status")
def queue_status():
    """
    –ü–æ–∫–∞–∑—É—î —Å—Ç–∞—Ç—É—Å Redis —á–µ—Ä–≥–∏ ML –æ–±—Ä–æ–±–∫–∏.
    """
    try:
        queue_len = redis.llen(ML_QUEUE)
        processing_count = redis.scard(ML_PROCESSING)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = redis.hgetall(ML_STATS)
        
        print("üìä ML Worker Queue Status")
        print("=" * 50)
        print(f"Queue length:        {queue_len}")
        print(f"Currently processing: {processing_count}")
        print()
        
        if stats:
            print("Statistics:")
            total = int(stats.get(b"total_processed", 0))
            positive = int(stats.get(b"positive_videos", 0))
            negative = int(stats.get(b"negative_videos", 0))
            avg_time = float(stats.get(b"avg_processing_time", 0))
            
            print(f"  Total processed:   {total}")
            print(f"  Positive videos:   {positive} ({positive/max(total,1)*100:.1f}%)")
            print(f"  Negative videos:   {negative} ({negative/max(total,1)*100:.1f}%)")
            print(f"  Avg processing:    {avg_time:.2f}s")
        else:
            print("No statistics available yet")
        
        print()
        
        # –ü–æ–∫–∞–∑—É—î–º–æ –∫—ñ–ª—å–∫–∞ –∑–∞–¥–∞—á –∑ —á–µ—Ä–≥–∏
        if queue_len > 0:
            print("Next tasks in queue:")
            tasks = redis.lrange(ML_QUEUE, 0, 4)
            for i, task in enumerate(tasks, 1):
                task_str = task.decode() if isinstance(task, bytes) else task
                s3_path = task_str.split("|")[0]
                print(f"  {i}. {s3_path}")
            
            if queue_len > 5:
                print(f"  ... and {queue_len - 5} more")
    
    except Exception as e:
        print(f"‚ùå Error: {e}")


@app.command("clear-queue")
def clear_queue(
    confirm: bool = typer.Option(False, "--yes", "-y", help="Skip confirmation")
):
    """
    –û—á–∏—â—É—î ML —á–µ—Ä–≥—É (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –æ–±–µ—Ä–µ–∂–Ω–æ).
    """
    queue_len = redis.llen(ML_QUEUE)
    
    if queue_len == 0:
        print("Queue is already empty")
        return
    
    if not confirm:
        response = typer.confirm(
            f"Are you sure you want to clear {queue_len} tasks from the queue?"
        )
        if not response:
            print("Cancelled")
            return
    
    redis.delete(ML_QUEUE)
    redis.delete(ML_PROCESSING)
    print(f"‚úì Cleared {queue_len} tasks from queue")


@app.command("partition")
def partition():
    """
    –°–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—è —ñ—Å–Ω—É—é—á–∏—Ö –≤—ñ–¥–µ–æ —É S3 –Ω–∞ 5-—Å–µ–∫—É–Ω–¥–Ω—ñ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∏.
    
    –£–í–ê–ì–ê: –¶—è –∫–æ–º–∞–Ω–¥–∞ –±—ñ–ª—å—à–µ –Ω–µ –ø–æ—Ç—Ä—ñ–±–Ω–∞ –¥–ª—è –Ω–æ–≤–æ–≥–æ –≤–æ—Ä–∫—Ñ–ª–æ—É,
    –æ—Å–∫—ñ–ª—å–∫–∏ ML –≤–æ—Ä–∫–µ—Ä –ø—Ä–∞—Ü—é—î –∑ –ø–æ–≤–Ω–∏–º–∏ –≤—ñ–¥–µ–æ.
    """
    print("‚ö†Ô∏è  WARNING: This command segments videos into 5s chunks")
    print("   The new ML workflow processes full videos instead")
    print()
    
    response = typer.confirm("Continue anyway?")
    if not response:
        print("Cancelled")
        return
    
    process_s3()


@app.command("bot")
def bot():
    """
    –ó–∞–ø—É—Å–∫ Telegram –±–æ—Ç–∞ –¥–ª—è —Ä–æ–∑–º—ñ—Ç–∫–∏ —Å–µ–≥–º–µ–Ω—Ç—ñ–≤.
    """
    print("ü§ñ Starting Label Bot")
    asyncio.run(run_bot())


@app.command("info")
def info():
    """
    –ü–æ–∫–∞–∑—É—î –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é —Å–∏—Å—Ç–µ–º–∏.
    """
    print("‚öôÔ∏è  System Configuration")
    print("=" * 50)
    print(f"Storage:              {settings.storage_backend}")
    print(f"S3 Endpoint:          {settings.s3_endpoint}")
    print(f"S3 Bucket:            {settings.s3_bucket}")
    print(f"Database:             {settings.db_dsn.split('@')[-1] if '@' in settings.db_dsn else 'local'}")
    print(f"Redis:                {settings.redis_dsn}")
    print()
    print("Crawler:")
    print(f"  Rotation interval:  {settings.channel_rotation_interval_hours}h")
    print(f"  Backfill since:     {settings.crawl_backfill_since}")
    print()
    print("ML Worker:")
    print(f"  Model path:         {settings.ml_model_path}")
    print(f"  Frames per second:  {settings.ml_frames_per_second}")
    print(f"  Positive threshold: {settings.ml_positive_threshold} frames")
    print(f"  Batch size:         {settings.ml_batch_size}")


if __name__ == "__main__":
    app()
